{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "We will be using the following packages for this notebook. \n",
    "You can install them with 'conda install <package>' or 'pip install <package>'"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "import pandas as pd\n",
    "import datetime as dt\n",
    "import pyproj\n",
    "import numpy as np\n",
    "import os\n",
    "\n",
    "from multiprocessing.pool import Pool"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Depending on the device, GPS trajectories can also contain measurements of velocity and acceleration. This dataset does not contain such information, but it can be calculated from XY-coordinates and timestamps of two points. \n",
    "\n",
    "velocity = distance(point1, point2) / timedelta(point1, point2)\n",
    "acceleration = velocitydifference(point1, point2) / timedelta(point1, point2)\n",
    "\n",
    "The important thing to take into account is that we first have to convert geographic (long, lat) coordinates to Euclidean coordinates, before we can calculate the velocity. This is called the Great-circle distance and takes the the curvature of the earth into account. \n",
    "\n",
    "The Python library pyproj can be used to convert between geographic (long, lat) to euclidean coordinates (x,y). Another great python library is geopy.\n",
    "\n",
    "\n",
    "see:\n",
    "\n",
    "https://en.wikipedia.org/wiki/Great-circle_distance\n",
    "\n",
    "https://github.com/jswhit/pyproj\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "geod = pyproj.Geod(ellps='WGS84')\n",
    "\n",
    "def to_datetime(string):\n",
    "    return dt.datetime.strptime(string, '%Y-%m-%d %H:%M:%S')\n",
    "\n",
    "def calculate_distance(long1, lat1, long2, lat2):\n",
    "    if lat1 == lat2 and long1 == long2:\n",
    "        return 0\n",
    "    if False in np.isfinite([long1, long2, lat1, lat2]):\n",
    "        return np.nan\n",
    "    if lat1 < -90 or lat1 > 90 or lat2 < -90 or lat2 > 90:\n",
    "        #raise ValueError('The range of latitudes seems to be invalid.')\n",
    "        return np.nan\n",
    "    if long1 < -180 or long1 > 180 or long2 < -180 or long2 > 180:\n",
    "        return np.nan\n",
    "        #raise ValueError('The range of longitudes seems to be invalid.')\n",
    "    angle1,angle2,distance = geod.inv(long1, lat1, long2, lat2)\n",
    "    return distance\n",
    "\n",
    "def calculate_velocity(distance, timedelta):\n",
    "    if timedelta.total_seconds() == 0: return np.nan\n",
    "    return distance / timedelta.total_seconds()\n",
    "\n",
    "def calculate_acceleration(velocity, velocity_next_position, timedelta):\n",
    "    delta_v = velocity_next_position - velocity\n",
    "    if timedelta.total_seconds() == 0: return np.nan\n",
    "    return delta_v / timedelta.total_seconds()\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "headers_trajectory = ['lat', 'long', 'null', 'altitude','timestamp_float', 'date', 'time']\n",
    "\n",
    "def load_trajectory_df(full_filename):\n",
    "    subfolder = full_filename.split('/')[-3]\n",
    "    trajectory_id = full_filename.split('/')[-1].split('.')[0]\n",
    "    \n",
    "    df = pd.read_csv(full_filename, skiprows = 6, header = None, names = headers_trajectory)\n",
    "   \n",
    "    df['datetime'] = df.apply(lambda z: to_datetime(z.date + ' ' + z.time), axis=1)\n",
    "    df['datetime_next_position'] = df['datetime'].shift(-1)\n",
    "    df['timedelta'] = df.apply(lambda z: z.datetime_next_position - z.datetime, axis=1)\n",
    "    df = df.drop(['datetime_next_position'], axis=1)\n",
    "    df = df.drop(['null', 'timestamp_float', 'date', 'time'], axis=1)\n",
    "    \n",
    "    \n",
    "    df['long_next_position'] = df['long'].shift(-1)\n",
    "    df['lat_next_position'] = df['lat'].shift(-1)\n",
    "    df['distance'] = df.apply(lambda z: calculate_distance(z.long, z.lat, z.long_next_position, z.lat_next_position), axis=1)\n",
    "    df = df.drop(['long_next_position', 'lat_next_position'], axis=1)\n",
    "    \n",
    "    df['velocity'] = df.apply(lambda z: calculate_velocity(z.distance, z.timedelta), axis=1)\n",
    "    df['velocity_next_position'] = df['velocity'].shift(-1)\n",
    "    df['acceleration'] = df.apply(lambda z: calculate_acceleration(z.velocity, z.velocity_next_position, z.timedelta), axis=1)\n",
    "    df = df.drop(['velocity_next_position'], axis=1)\n",
    "    \n",
    "    df['trajectory_id'] = trajectory_id\n",
    "    df['subfolder'] = subfolder\n",
    "    df['labels'] = ''\n",
    "    calculate_agg_features(df)\n",
    "    return df\n",
    "\n",
    "def load_labels_df(filename):\n",
    "    df = pd.read_csv(filename, sep='\\t')\n",
    "    df['start_time'] = df['Start Time'].apply(lambda x: dt.datetime.strptime(x, '%Y/%m/%d %H:%M:%S'))\n",
    "    df['end_time'] = df['End Time'].apply(lambda x: dt.datetime.strptime(x, '%Y/%m/%d %H:%M:%S'))\n",
    "    df['labels'] = df['Transportation Mode']\n",
    "    df = df.drop(['End Time', 'Start Time', 'Transportation Mode'], axis=1)\n",
    "    return df\n",
    "\n",
    "def calculate_agg_features(df):\n",
    "    #This method calculates the aggregated feature and \n",
    "    #saves them in the original df as well as an metadata df.\n",
    "    v_ave = np.nanmean(df['velocity'].values)\n",
    "    v_med = np.nanmedian(df['velocity'].values)\n",
    "    v_max = np.nanmax(df['velocity'].values)\n",
    "    a_ave = np.nanmean(df['acceleration'].values)\n",
    "    a_med = np.nanmedian(df['acceleration'].values)\n",
    "    a_max = np.nanmax(df['acceleration'].values)\n",
    "   \n",
    "    df.loc[:, 'v_ave'] = v_ave\n",
    "    df.loc[:, 'v_med'] = v_med\n",
    "    df.loc[:, 'v_max'] = v_max\n",
    "    df.loc[:, 'a_ave'] = a_ave\n",
    "    df.loc[:, 'a_med'] = a_med\n",
    "    df.loc[:, 'a_max'] = a_max\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "052 104\n"
     ]
    }
   ],
   "source": [
    "LABELS_FILE = 'labels.txt'\n",
    "MAIN_FOLDER = '../Data/labeled/'\n",
    "TRAJ_FOLDER = 'Trajectory/'\n",
    "OUTPUT_FOLDER = '../processed_data/'\n",
    "POOLSIZE = 10\n",
    "\n",
    "if not os.path.exists(OUTPUT_FOLDER):\n",
    "    os.makedirs(OUTPUT_FOLDER)\n",
    "directories = os.listdir(MAIN_FOLDER)\n",
    "\n",
    "for subfolder in directories:\n",
    "    list_df_traj = []\n",
    "    subfolder_ = MAIN_FOLDER + subfolder + '/'\n",
    "    traj_folder = MAIN_FOLDER + subfolder + '/' + TRAJ_FOLDER\n",
    "    traj_files = os.listdir(traj_folder)\n",
    "    \n",
    "    traj_files_full_path = [traj_folder + traj_file for traj_file in traj_files]\n",
    "    print(subfolder, len(traj_files_full_path))\n",
    "    \n",
    "    #multiprocessing does not work well in the jupyter notebook environment.\n",
    "    #outside of jupyter you can use multiprocessing to speed up the process\n",
    "    #pool = Pool(POOLSIZE)\n",
    "    #for df in pool.imap_unordered(load_trajectory_df, traj_files_full_path):\n",
    "    #    list_df_traj.append(df)\n",
    "    \n",
    "    for file in traj_files_full_path:\n",
    "        list_df_traj.append(load_trajectory_df(file))\n",
    "    \n",
    "    df_traj_all = pd.concat(list_df_traj)\n",
    "    list_df_traj = []\n",
    "    \n",
    "    if LABELS_FILE in os.listdir(subfolder_):\n",
    "        filename = subfolder_ + LABELS_FILE\n",
    "        df_labels = load_labels_df(filename)\n",
    "        for idx in df_labels.index.values:\n",
    "            st = df_labels.ix[idx]['start_time']\n",
    "            et = df_labels.ix[idx]['end_time']\n",
    "            labels = df_labels.ix[idx]['labels']\n",
    "            if labels:\n",
    "                df_traj_all.loc[(df_traj_all['datetime'] >= st) & \n",
    "                                (df_traj_all['datetime'] <= et), 'labels'] = labels\n",
    "\n",
    "    output_filename = OUTPUT_FOLDER + subfolder + '.csv'\n",
    "    df_traj_all.to_csv(output_filename)\n",
    "    del df_traj_all"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "anaconda-cloud": {},
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.6.0"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 1
}
